{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install minatar\n!pip install dm-haiku\n!pip install distrax\n!pip install pgx\n!pip install omegaconf\n!pip install learn2learn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T17:48:38.529255Z","iopub.execute_input":"2024-12-07T17:48:38.529646Z","iopub.status.idle":"2024-12-07T17:50:02.514573Z","shell.execute_reply.started":"2024-12-07T17:48:38.529595Z","shell.execute_reply":"2024-12-07T17:50:02.513748Z"}},"outputs":[{"name":"stdout","text":"Collecting minatar\n  Downloading MinAtar-1.0.15-py3-none-any.whl.metadata (685 bytes)\nRequirement already satisfied: cycler>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from minatar) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from minatar) (1.4.5)\nRequirement already satisfied: matplotlib>=3.0.3 in /opt/conda/lib/python3.10/site-packages (from minatar) (3.7.5)\nRequirement already satisfied: numpy>=1.16.2 in /opt/conda/lib/python3.10/site-packages (from minatar) (1.26.4)\nRequirement already satisfied: pandas>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from minatar) (2.2.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from minatar) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from minatar) (2.9.0.post0)\nRequirement already satisfied: pytz>=2018.9 in /opt/conda/lib/python3.10/site-packages (from minatar) (2024.1)\nRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.10/site-packages (from minatar) (1.14.1)\nRequirement already satisfied: seaborn>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from minatar) (0.12.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from minatar) (1.16.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.3->minatar) (1.2.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.3->minatar) (4.53.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.3->minatar) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.3->minatar) (10.3.0)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.2->minatar) (2024.1)\nDownloading MinAtar-1.0.15-py3-none-any.whl (16 kB)\nInstalling collected packages: minatar\nSuccessfully installed minatar-1.0.15\nCollecting dm-haiku\n  Downloading dm_haiku-0.0.13-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: absl-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from dm-haiku) (1.4.0)\nCollecting jmp>=0.0.2 (from dm-haiku)\n  Downloading jmp-0.0.4-py3-none-any.whl.metadata (8.9 kB)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from dm-haiku) (1.26.4)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from dm-haiku) (0.9.0)\nDownloading dm_haiku-0.0.13-py3-none-any.whl (373 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.9/373.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading jmp-0.0.4-py3-none-any.whl (18 kB)\nInstalling collected packages: jmp, dm-haiku\nSuccessfully installed dm-haiku-0.0.13 jmp-0.0.4\nCollecting distrax\n  Downloading distrax-0.1.5-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: absl-py>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from distrax) (1.4.0)\nRequirement already satisfied: chex>=0.1.8 in /opt/conda/lib/python3.10/site-packages (from distrax) (0.1.86)\nRequirement already satisfied: jax>=0.1.55 in /opt/conda/lib/python3.10/site-packages (from distrax) (0.4.26)\nRequirement already satisfied: jaxlib>=0.1.67 in /opt/conda/lib/python3.10/site-packages (from distrax) (0.4.26.dev20240620)\nRequirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from distrax) (1.26.4)\nRequirement already satisfied: tensorflow-probability>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from distrax) (0.24.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from chex>=0.1.8->distrax) (4.12.2)\nRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chex>=0.1.8->distrax) (0.12.1)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.1.55->distrax) (0.3.2)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax>=0.1.55->distrax) (3.3.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax>=0.1.55->distrax) (1.14.1)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability>=0.15.0->distrax) (1.16.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability>=0.15.0->distrax) (5.1.1)\nRequirement already satisfied: cloudpickle>=1.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability>=0.15.0->distrax) (3.0.0)\nRequirement already satisfied: gast>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability>=0.15.0->distrax) (0.5.4)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability>=0.15.0->distrax) (0.1.8)\nDownloading distrax-0.1.5-py3-none-any.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: distrax\nSuccessfully installed distrax-0.1.5\nCollecting pgx\n  Downloading pgx-2.5.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: jax>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pgx) (0.4.26)\nRequirement already satisfied: typing_extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pgx) (4.12.2)\nCollecting svgwrite (from pgx)\n  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.4.6->pgx) (0.3.2)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from jax>=0.4.6->pgx) (1.26.4)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax>=0.4.6->pgx) (3.3.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax>=0.4.6->pgx) (1.14.1)\nDownloading pgx-2.5.0-py3-none-any.whl (436 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.7/436.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: svgwrite, pgx\nSuccessfully installed pgx-2.5.0 svgwrite-1.4.3\nCollecting omegaconf\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from omegaconf) (6.0.2)\nDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=d210f667d8ba1dfacc09a43af62f020e6e1803e8bc0f554d9b2751c6d36e8db1\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\nSuccessfully built antlr4-python3-runtime\nInstalling collected packages: antlr4-python3-runtime, omegaconf\nSuccessfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\nCollecting learn2learn\n  Downloading learn2learn-0.2.0.tar.gz (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.10/site-packages (from learn2learn) (1.26.4)\nRequirement already satisfied: gym>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from learn2learn) (0.26.2)\nRequirement already satisfied: torch>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from learn2learn) (2.4.0)\nRequirement already satisfied: torchvision>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from learn2learn) (0.19.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from learn2learn) (1.14.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from learn2learn) (2.32.3)\nCollecting gsutil (from learn2learn)\n  Downloading gsutil-5.32.tar.gz (3.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from learn2learn) (4.66.4)\nCollecting qpth>=0.0.15 (from learn2learn)\n  Downloading qpth-0.0.18.tar.gz (16 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym>=0.14.0->learn2learn) (3.0.0)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym>=0.14.0->learn2learn) (0.0.8)\nCollecting cvxpy>=1.1.0 (from qpth>=0.0.15->learn2learn)\n  Downloading cvxpy-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->learn2learn) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->learn2learn) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->learn2learn) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->learn2learn) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->learn2learn) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->learn2learn) (2024.6.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.3.0->learn2learn) (10.3.0)\nCollecting argcomplete>=3.5.1 (from gsutil->learn2learn)\n  Downloading argcomplete-3.5.2-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from gsutil->learn2learn) (1.7)\nRequirement already satisfied: fasteners>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from gsutil->learn2learn) (0.19)\nCollecting gcs-oauth2-boto-plugin>=3.2 (from gsutil->learn2learn)\n  Downloading gcs-oauth2-boto-plugin-3.2.tar.gz (22 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting google-apitools>=0.5.32 (from gsutil->learn2learn)\n  Downloading google_apitools-0.5.32-py3-none-any.whl.metadata (2.3 kB)\nCollecting httplib2==0.20.4 (from gsutil->learn2learn)\n  Downloading httplib2-0.20.4-py3-none-any.whl.metadata (2.5 kB)\nCollecting google-reauth>=0.1.0 (from gsutil->learn2learn)\n  Downloading google_reauth-0.1.1-py2.py3-none-any.whl.metadata (2.6 kB)\nCollecting monotonic>=1.4 (from gsutil->learn2learn)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: pyOpenSSL<=24.2.1,>=0.13 in /opt/conda/lib/python3.10/site-packages (from gsutil->learn2learn) (24.0.0)\nCollecting retry_decorator>=1.0.0 (from gsutil->learn2learn)\n  Downloading retry_decorator-1.1.1.tar.gz (3.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from gsutil->learn2learn) (1.16.0)\nCollecting google-auth==2.17.0 (from google-auth[aiohttp]==2.17.0->gsutil->learn2learn)\n  Downloading google_auth-2.17.0-py2.py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: google-auth-httplib2>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from gsutil->learn2learn) (0.2.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (4.9)\nRequirement already satisfied: aiohttp<4.0.0dev,>=3.6.2 in /opt/conda/lib/python3.10/site-packages (from google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (3.9.5)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2==0.20.4->gsutil->learn2learn) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->learn2learn) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->learn2learn) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->learn2learn) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->learn2learn) (2024.8.30)\nCollecting osqp>=0.6.2 (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn)\n  Downloading osqp-0.6.7.post3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\nCollecting clarabel>=0.5.0 (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn)\n  Downloading clarabel-0.9.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nCollecting scs>=3.2.4.post1 (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn)\n  Downloading scs-3.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\nCollecting rsa<5,>=3.1.4 (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn)\n  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\nCollecting boto>=2.29.1 (from gcs-oauth2-boto-plugin>=3.2->gsutil->learn2learn)\n  Downloading boto-2.49.0-py2.py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: oauth2client>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from gcs-oauth2-boto-plugin>=3.2->gsutil->learn2learn) (4.1.3)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (0.6.0)\nRequirement already satisfied: pyu2f in /opt/conda/lib/python3.10/site-packages (from google-reauth>=0.1.0->gsutil->learn2learn) (0.1.5)\nRequirement already satisfied: cryptography<43,>=41.0.5 in /opt/conda/lib/python3.10/site-packages (from pyOpenSSL<=24.2.1,>=0.13->gsutil->learn2learn) (42.0.8)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.1.0->learn2learn) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.1.0->learn2learn) (1.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (4.0.3)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography<43,>=41.0.5->pyOpenSSL<=24.2.1,>=0.13->gsutil->learn2learn) (1.16.0)\nCollecting qdldl (from osqp>=0.6.2->cvxpy>=1.1.0->qpth>=0.0.15->learn2learn)\n  Downloading qdldl-0.1.7.post4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography<43,>=41.0.5->pyOpenSSL<=24.2.1,>=0.13->gsutil->learn2learn) (2.22)\nDownloading google_auth-2.17.0-py2.py3-none-any.whl (178 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.1/178.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading argcomplete-3.5.2-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cvxpy-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rsa-4.7.2-py3-none-any.whl (34 kB)\nDownloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_reauth-0.1.1-py2.py3-none-any.whl (17 kB)\nDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading clarabel-0.9.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading osqp-0.6.7.post3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scs-3.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading qdldl-0.1.7.post4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: learn2learn, qpth, gsutil, gcs-oauth2-boto-plugin, retry_decorator\n  Building wheel for learn2learn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for learn2learn: filename=learn2learn-0.2.0-cp310-cp310-linux_x86_64.whl size=402378 sha256=593df3e8c05c2c27b4a3e09b5d8af075db219aa47317c4c0e25468659e02990d\n  Stored in directory: /root/.cache/pip/wheels/89/2c/13/c538cd229cdfc6c15a9d3cf64d2bb8220e205ea0f63ecb5fbe\n  Building wheel for qpth (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for qpth: filename=qpth-0.0.18-py3-none-any.whl size=19548 sha256=dcebc09f9d38fae048cc78f44000371264e2c64ae09580045f96c4055ba48204\n  Stored in directory: /root/.cache/pip/wheels/7b/80/c0/2b553cc21315757f3e03846eb747795bf2a57d15bc14ef80cf\n  Building wheel for gsutil (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gsutil: filename=gsutil-5.32-py3-none-any.whl size=3789757 sha256=7d3badddc591355039926f49f9785ec60c00348971e74f9ffb4fd78f5786e1e8\n  Stored in directory: /root/.cache/pip/wheels/5a/0d/47/b2ab01f42d51b8ccd5f871e5f5754505021dd6492e06cfda0e\n  Building wheel for gcs-oauth2-boto-plugin (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gcs-oauth2-boto-plugin: filename=gcs_oauth2_boto_plugin-3.2-py3-none-any.whl size=24469 sha256=c9b6ba7551d43019af9991d353ef4ddabe58598e643f6219a5f9441f712ccd3f\n  Stored in directory: /root/.cache/pip/wheels/71/7a/33/4cc4d6af226ef2e5092b72e7a0b7bc49b42467c928dbb191d3\n  Building wheel for retry_decorator (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for retry_decorator: filename=retry_decorator-1.1.1-py2.py3-none-any.whl size=3641 sha256=7abc69c5fc94b1c2f9b028b363bd022146a78df49b658883c4a97749ddc7d64f\n  Stored in directory: /root/.cache/pip/wheels/dd/ac/77/8c54eac0d373d9eacfbe42599710c9bf91b4c5985297f6922a\nSuccessfully built learn2learn qpth gsutil gcs-oauth2-boto-plugin retry_decorator\nInstalling collected packages: retry_decorator, monotonic, boto, rsa, httplib2, argcomplete, scs, qdldl, google-reauth, google-auth, clarabel, osqp, google-apitools, gcs-oauth2-boto-plugin, cvxpy, qpth, gsutil, learn2learn\n  Attempting uninstall: rsa\n    Found existing installation: rsa 4.9\n    Uninstalling rsa-4.9:\n      Successfully uninstalled rsa-4.9\n  Attempting uninstall: httplib2\n    Found existing installation: httplib2 0.21.0\n    Uninstalling httplib2-0.21.0:\n      Successfully uninstalled httplib2-0.21.0\n  Attempting uninstall: google-auth\n    Found existing installation: google-auth 2.30.0\n    Uninstalling google-auth-2.30.0:\n      Successfully uninstalled google-auth-2.30.0\n  Attempting uninstall: google-apitools\n    Found existing installation: google-apitools 0.5.31\n    Uninstalling google-apitools-0.5.31:\n      Successfully uninstalled google-apitools-0.5.31\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\nbeatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed argcomplete-3.5.2 boto-2.49.0 clarabel-0.9.0 cvxpy-1.6.0 gcs-oauth2-boto-plugin-3.2 google-apitools-0.5.32 google-auth-2.17.0 google-reauth-0.1.1 gsutil-5.32 httplib2-0.20.4 learn2learn-0.2.0 monotonic-1.6 osqp-0.6.7.post3 qdldl-0.1.7.post4 qpth-0.0.18 retry_decorator-1.1.1 rsa-4.7.2 scs-3.2.7\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\nimport sys\nimport jax\nimport jax.numpy as jnp\nimport haiku as hk\nimport optax\nfrom typing import NamedTuple, Literal\nimport distrax\nimport pgx\nfrom pgx.experimental import auto_reset\nimport time\n\nimport pickle\nfrom omegaconf import OmegaConf\nfrom pydantic import BaseModel\nimport wandb\nimport learn2learn as l2l\nimport jax\nimport jax.numpy as jnp\nimport flax.linen as nn\nimport numpy as np\nimport optax\nfrom flax.linen.initializers import constant, orthogonal\nfrom typing import Sequence, NamedTuple, Any\nfrom flax.training.train_state import TrainState\nimport distrax\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T17:50:02.516806Z","iopub.execute_input":"2024-12-07T17:50:02.517574Z","iopub.status.idle":"2024-12-07T17:50:24.307644Z","shell.execute_reply.started":"2024-12-07T17:50:02.517533Z","shell.execute_reply":"2024-12-07T17:50:24.306931Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class PPOConfig(BaseModel):\n    env_name: Literal[\n        \"minatar-breakout\",\n        \"minatar-freeway\",\n        \"minatar-space_invaders\",\n        \"minatar-asterix\",\n        \"minatar-seaquest\",\n    ] = \"minatar-space_invaders\" \n    seed: int = 0\n    lr: float = 1e-3\n    num_envs: int = 64 \n    num_eval_envs: int = 100\n    num_steps: int = 128\n    total_timesteps: int = int(1e7)\n    update_epochs: int = 4\n    minibatch_size: int = 4096\n    gamma: float = 0.99\n    gae_lambda: float = 0.95\n    clip_eps: float = 0.2\n    ent_coef: float = 0.01\n    vf_coef: float = 0.5\n    max_grad_norm: float = 0.5\n    wandb_entity: str = \"nonarruginitocalamarodiferro-usi\" \n    wandb_project: str = \"pgx-minatar-ppo\"  \n    save_model: bool = False\n\n    class Config:\n        extra = \"forbid\"\n\n\nargs = PPOConfig(\n    env_name=\"minatar-space_invaders\", \n    seed=0,\n    lr=1e-3,\n    num_envs=64,\n    num_eval_envs=100,\n    num_steps=128,\n    total_timesteps=int(1e7), \n    update_epochs=4,\n    minibatch_size=4096, \n    gamma=0.99,\n    gae_lambda=0.90,\n    clip_eps=0.25,\n    ent_coef=0.005, \n    vf_coef=0.5,\n    max_grad_norm=0.5, \n    wandb_entity=\"nonarruginitocalamarodiferro-usi\", \n    wandb_project=\"pgx-minatar-ppo\", \n    save_model=False  \n)\n\nprint(args)  # To verify your updated configuration\n\n# Initialize environment\nenv = pgx.make(str(args.env_name))\n\nnum_updates = args.total_timesteps // args.num_envs // args.num_steps\nnum_minibatches = args.num_envs * args.num_steps // args.minibatch_size\n\n\n\n\nclass ActorCritic(hk.Module):\n    def __init__(self, num_actions, activation=\"tanh\"):\n        super().__init__()\n        self.num_actions = num_actions\n        self.activation = activation\n        assert activation in [\"relu\", \"tanh\"]\n\n    def __call__(self, x):\n        x = x.astype(jnp.float32)\n        if self.activation == \"relu\":\n            activation = jax.nn.relu\n        else:\n            activation = jax.nn.tanh\n        x = hk.Conv2D(32, kernel_shape=2)(x)\n        x = jax.nn.relu(x)\n        x = hk.avg_pool(x, window_shape=(2, 2),\n                        strides=(2, 2), padding=\"VALID\")\n        x = x.reshape((x.shape[0], -1))  # flatten\n        x = hk.Linear(64)(x)\n        x = jax.nn.relu(x)\n        actor_mean = hk.Linear(64)(x)\n        actor_mean = activation(actor_mean)\n        actor_mean = hk.Linear(64)(actor_mean)\n        actor_mean = activation(actor_mean)\n        actor_mean = hk.Linear(self.num_actions)(actor_mean)\n\n        critic = hk.Linear(64)(x)\n        critic = activation(critic)\n        critic = hk.Linear(64)(critic)\n        critic = activation(critic)\n        critic = hk.Linear(1)(critic)\n\n        return actor_mean, jnp.squeeze(critic, axis=-1)\n\n\ndef forward_fn(x, is_eval=False):\n    net = ActorCritic(env.num_actions, activation=\"tanh\")\n    logits, value = net(x)\n    return logits, value\n\n\nforward = hk.without_apply_rng(hk.transform(forward_fn))\n\n\noptimizer = optax.chain(optax.clip_by_global_norm(\n    args.max_grad_norm), optax.adam(args.lr, eps=1e-5))\n\n\nclass Transition(NamedTuple):\n    done: jnp.ndarray\n    action: jnp.ndarray\n    value: jnp.ndarray\n    reward: jnp.ndarray\n    log_prob: jnp.ndarray\n    obs: jnp.ndarray\n\n\ndef make_update_fn():\n    # TRAIN LOOP\n    def _update_step(runner_state):\n        # COLLECT TRAJECTORIES\n        step_fn = jax.vmap(auto_reset(env.step, env.init))\n\n        def _env_step(runner_state, unused):\n            params, opt_state, env_state, last_obs, rng = runner_state\n            # SELECT ACTION\n            rng, _rng = jax.random.split(rng)\n            logits, value = forward.apply(params, last_obs)\n            pi = distrax.Categorical(logits=logits)\n            action = pi.sample(seed=_rng)\n            log_prob = pi.log_prob(action)\n\n            # STEP ENV\n            rng, _rng = jax.random.split(rng)\n            keys = jax.random.split(_rng, env_state.observation.shape[0])\n            env_state = step_fn(env_state, action, keys)\n            transition = Transition(\n                env_state.terminated,\n                action,\n                value,\n                jnp.squeeze(env_state.rewards),\n                log_prob,\n                last_obs\n            )\n            runner_state = (params, opt_state, env_state,\n                            env_state.observation, rng)\n            return runner_state, transition\n\n        runner_state, traj_batch = jax.lax.scan(\n            _env_step, runner_state, None, args.num_steps\n        )\n\n        # CALCULATE ADVANTAGE\n        params, opt_state, env_state, last_obs, rng = runner_state\n        _, last_val = forward.apply(params, last_obs)\n\n        def _calculate_gae(traj_batch, last_val):\n            def _get_advantages(gae_and_next_value, transition):\n                gae, next_value = gae_and_next_value\n                done, value, reward = (\n                    transition.done,\n                    transition.value,\n                    transition.reward,\n                )\n                delta = reward + args.gamma * next_value * (1 - done) - value\n                gae = (\n                    delta\n                    + args.gamma * args.gae_lambda * (1 - done) * gae\n                )\n                return (gae, value), gae\n\n            _, advantages = jax.lax.scan(\n                _get_advantages,\n                (jnp.zeros_like(last_val), last_val),\n                traj_batch,\n                reverse=True,\n                unroll=16,\n            )\n            return advantages, advantages + traj_batch.value\n\n        advantages, targets = _calculate_gae(traj_batch, last_val)\n\n        # UPDATE NETWORK\n        def _update_epoch(update_state, unused):\n            def _update_minbatch(tup, batch_info):\n                params, opt_state = tup\n                traj_batch, advantages, targets = batch_info\n\n                def _loss_fn(params, traj_batch, gae, targets):\n                    # RERUN NETWORK\n                    logits, value = forward.apply(params, traj_batch.obs)\n                    pi = distrax.Categorical(logits=logits)\n                    log_prob = pi.log_prob(traj_batch.action)\n\n                    # CALCULATE VALUE LOSS\n                    value_pred_clipped = traj_batch.value + (\n                        value - traj_batch.value\n                    ).clip(-args.clip_eps, args.clip_eps)\n                    value_losses = jnp.square(value - targets)\n                    value_losses_clipped = jnp.square(\n                        value_pred_clipped - targets)\n                    value_loss = (\n                        0.5 * jnp.maximum(value_losses,\n                                          value_losses_clipped).mean()\n                    )\n\n                    # CALCULATE ACTOR LOSS\n                    ratio = jnp.exp(log_prob - traj_batch.log_prob)\n                    gae = (gae - gae.mean()) / (gae.std() + 1e-8)\n                    loss_actor1 = ratio * gae\n                    loss_actor2 = (\n                        jnp.clip(\n                            ratio,\n                            1.0 - args.clip_eps,\n                            1.0 + args.clip_eps,\n                        )\n                        * gae\n                    )\n                    loss_actor = -jnp.minimum(loss_actor1, loss_actor2)\n                    loss_actor = loss_actor.mean()\n                    entropy = pi.entropy().mean()\n\n                    total_loss = (\n                        loss_actor\n                        + args.vf_coef * value_loss\n                        - args.ent_coef * entropy\n                    )\n                    return total_loss, (value_loss, loss_actor, entropy)\n\n                grad_fn = jax.value_and_grad(_loss_fn, has_aux=True)\n                total_loss, grads = grad_fn(\n                    params, traj_batch, advantages, targets)\n                updates, opt_state = optimizer.update(grads, opt_state)\n                params = optax.apply_updates(params, updates)\n                return (params, opt_state), total_loss\n\n            params, opt_state, traj_batch, advantages, targets, rng = update_state\n            rng, _rng = jax.random.split(rng)\n            batch_size = args.minibatch_size * num_minibatches\n            assert (\n                batch_size == args.num_steps * args.num_envs\n            ), \"batch size must be equal to number of steps * number of envs\"\n            permutation = jax.random.permutation(_rng, batch_size)\n            batch = (traj_batch, advantages, targets)\n            batch = jax.tree_util.tree_map(\n                lambda x: x.reshape((batch_size,) + x.shape[2:]), batch\n            )\n            shuffled_batch = jax.tree_util.tree_map(\n                lambda x: jnp.take(x, permutation, axis=0), batch\n            )\n            minibatches = jax.tree_util.tree_map(\n                lambda x: jnp.reshape(\n                    x, [num_minibatches, -1] + list(x.shape[1:])\n                ),\n                shuffled_batch,\n            )\n            (params, opt_state),  total_loss = jax.lax.scan(\n                _update_minbatch, (params, opt_state), minibatches\n            )\n            update_state = (params, opt_state, traj_batch,\n                            advantages, targets, rng)\n            return update_state, total_loss\n\n        update_state = (params, opt_state, traj_batch,\n                        advantages, targets, rng)\n        update_state, loss_info = jax.lax.scan(\n            _update_epoch, update_state, None, args.update_epochs\n        )\n        params, opt_state, _, _, _, rng = update_state\n\n        runner_state = (params, opt_state, env_state, last_obs, rng)\n        return runner_state, loss_info\n    return _update_step\n\n\n@jax.jit\ndef evaluate(params, rng_key):\n    step_fn = jax.vmap(env.step)\n    rng_key, sub_key = jax.random.split(rng_key)\n    subkeys = jax.random.split(sub_key, args.num_eval_envs)\n    state = jax.vmap(env.init)(subkeys)\n    R = jnp.zeros_like(state.rewards)\n\n    def cond_fn(tup):\n        state, _, _ = tup\n        return ~state.terminated.all()\n\n    def loop_fn(tup):\n        state, R, rng_key = tup\n        logits, value = forward.apply(params, state.observation)\n        # action = logits.argmax(axis=-1)\n        pi = distrax.Categorical(logits=logits)\n        rng_key, _rng = jax.random.split(rng_key)\n        action = pi.sample(seed=_rng)\n        rng_key, _rng = jax.random.split(rng_key)\n        keys = jax.random.split(_rng, state.observation.shape[0])\n        state = step_fn(state, action, keys)\n        return state, R + state.rewards, rng_key\n    state, R, _ = jax.lax.while_loop(cond_fn, loop_fn, (state, R, rng_key))\n    return R.mean()\n\n\ndef train(rng):\n    tt = 0\n    st = time.time()\n    # INIT NETWORK\n    rng, _rng = jax.random.split(rng)\n    init_x = jnp.zeros((1, ) + env.observation_shape)\n    params = forward.init(_rng, init_x)\n    opt_state = optimizer.init(params=params)\n\n    # INIT UPDATE FUNCTION\n    _update_step = make_update_fn()\n    jitted_update_step = jax.jit(_update_step)\n\n    # INIT ENV\n    rng, _rng = jax.random.split(rng)\n    reset_rng = jax.random.split(_rng, args.num_envs)\n    env_state = jax.jit(jax.vmap(env.init))(reset_rng)\n\n    rng, _rng = jax.random.split(rng)\n    runner_state = (params, opt_state, env_state, env_state.observation, _rng)\n\n    # warm up\n    _, _ = jitted_update_step(runner_state)\n\n    steps = 0\n\n    # initial evaluation\n    et = time.time()  # exclude evaluation time\n    tt += et - st\n    rng, _rng = jax.random.split(rng)\n    eval_R = evaluate(runner_state[0], _rng)\n    log = {\"sec\": tt, f\"{args.env_name}/eval_R\": float(eval_R), \"steps\": steps}\n    print(log)\n    wandb.log(log)\n    st = time.time()\n\n    for i in range(num_updates):\n        runner_state, loss_info = jitted_update_step(runner_state)\n        steps += args.num_envs * args.num_steps\n\n        # evaluation\n        et = time.time()  # exclude evaluation time\n        tt += et - st\n        rng, _rng = jax.random.split(rng)\n        eval_R = evaluate(runner_state[0], _rng)\n        log = {\"sec\": tt, f\"{args.env_name}/eval_R\": float(eval_R), \"steps\": steps}\n        print(log)\n        wandb.log(log)\n        st = time.time()\n\n    return runner_state\n\nif __name__ == \"__main__\":\n    wandb.init(project=args.wandb_project, entity=args.wandb_entity, config=args.dict())\n    rng = jax.random.PRNGKey(args.seed)\n    out = train(rng)\n    if args.save_model:\n        with open(f\"{args.env_name}-seed={args.seed}.ckpt\", \"wb\") as f:\n            pickle.dump(out[0], f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:11:18.944542Z","iopub.execute_input":"2024-12-06T13:11:18.944825Z","iopub.status.idle":"2024-12-06T13:11:29.076455Z","shell.execute_reply.started":"2024-12-06T13:11:18.944799Z","shell.execute_reply":"2024-12-06T13:11:29.074694Z"}},"outputs":[{"name":"stdout","text":"env_name='minatar-space_invaders' seed=0 lr=0.001 num_envs=64 num_eval_envs=100 num_steps=128 total_timesteps=10000000 update_epochs=4 minibatch_size=4096 gamma=0.99 gae_lambda=0.9 clip_eps=0.25 ent_coef=0.005 vf_coef=0.5 max_grad_norm=0.5 wandb_entity='nonarruginitocalamarodiferro-usi' wandb_project='pgx-minatar-ppo' save_model=False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:hdlfcc0k) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.017 MB of 0.017 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dry-dawn-69</strong> at: <a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo/runs/hdlfcc0k' target=\"_blank\">https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo/runs/hdlfcc0k</a><br/> View project at: <a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo' target=\"_blank\">https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241206_130835-hdlfcc0k/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:hdlfcc0k). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_131118-vi647d8b</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo/runs/vi647d8b' target=\"_blank\">breezy-smoke-70</a></strong> to <a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo' target=\"_blank\">https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo/runs/vi647d8b' target=\"_blank\">https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo/runs/vi647d8b</a>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 360\u001b[0m\n\u001b[1;32m    358\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mwandb_project, entity\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mwandb_entity, config\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdict())\n\u001b[1;32m    359\u001b[0m rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(args\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m--> 360\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39msave_model:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-seed=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n","Cell \u001b[0;32mIn[13], line 335\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(rng)\u001b[0m\n\u001b[1;32m    333\u001b[0m tt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m et \u001b[38;5;241m-\u001b[39m st\n\u001b[1;32m    334\u001b[0m rng, _rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(rng)\n\u001b[0;32m--> 335\u001b[0m eval_R \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_rng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m log \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msec\u001b[39m\u001b[38;5;124m\"\u001b[39m: tt, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/eval_R\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(eval_R), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m: steps}\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mprint\u001b[39m(log)\n","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/pjit.py:298\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 298\u001b[0m   outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m      \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m   executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[1;32m    301\u001b[0m   maybe_fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m    302\u001b[0m       executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[1;32m    303\u001b[0m       jit_info\u001b[38;5;241m.\u001b[39mabstracted_axes)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/pjit.py:176\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m   args_flat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39minit_states, \u001b[38;5;241m*\u001b[39margs_flat]\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mDeviceAssignmentMismatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    178\u001b[0m   fails, \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/core.py:2788\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2784\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[1;32m   2785\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   2786\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[1;32m   2787\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2788\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/core.py:425\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 425\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/core.py:913\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 913\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/pjit.py:1488\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1485\u001b[0m has_explicit_sharding \u001b[38;5;241m=\u001b[39m _pjit_explicit_sharding(\n\u001b[1;32m   1486\u001b[0m     in_shardings, out_shardings, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xla_extension_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m226\u001b[39m:\n\u001b[0;32m-> 1488\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_impl_cache_miss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_argnums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_registry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpxla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshard_arg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxla_extension_version\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m229\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpxla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp_shard_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m   1492\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_get_cpp_global_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhas_explicit_sharding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m xc\u001b[38;5;241m.\u001b[39m_xla\u001b[38;5;241m.\u001b[39mpjit(name, f, call_impl_cache_miss, [], [], donated_argnums,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m                       tree_util\u001b[38;5;241m.\u001b[39mdispatch_registry,\n\u001b[1;32m   1496\u001b[0m                       _get_cpp_global_cache(has_explicit_sharding))(\u001b[38;5;241m*\u001b[39margs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/pjit.py:1471\u001b[0m, in \u001b[0;36m_pjit_call_impl.<locals>.call_impl_cache_miss\u001b[0;34m(*args_, **kwargs_)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_impl_cache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_):\n\u001b[0;32m-> 1471\u001b[0m   out_flat, compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_pjit_call_impl_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m      \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m      \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1476\u001b[0m   fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m   1477\u001b[0m       compiled, tree_structure(out_flat), args, out_flat, [], jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[1;32m   1478\u001b[0m       \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1479\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out_flat, fastpath_data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/pjit.py:1406\u001b[0m, in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _most_recent_pjit_call_executable\n\u001b[1;32m   1399\u001b[0m in_shardings \u001b[38;5;241m=\u001b[39m _resolve_in_shardings(\n\u001b[1;32m   1400\u001b[0m     args, in_shardings, out_shardings,\n\u001b[1;32m   1401\u001b[0m     resource_env\u001b[38;5;241m.\u001b[39mphysical_mesh \u001b[38;5;28;01mif\u001b[39;00m resource_env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1403\u001b[0m compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_pjit_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlowering_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoweringParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1407\u001b[0m _most_recent_pjit_call_executable\u001b[38;5;241m.\u001b[39mweak_key_dict[jaxpr] \u001b[38;5;241m=\u001b[39m compiled\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2369\u001b[0m, in \u001b[0;36mMeshComputation.compile\u001b[0;34m(self, compiler_options)\u001b[0m\n\u001b[1;32m   2367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(\u001b[38;5;28mself\u001b[39m, compiler_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MeshExecutable:\n\u001b[1;32m   2368\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m compiler_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2369\u001b[0m     executable \u001b[38;5;241m=\u001b[39m \u001b[43mUnloadedMeshExecutable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompiler_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compiler_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2373\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executable \u001b[38;5;241m=\u001b[39m executable\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2908\u001b[0m, in \u001b[0;36mUnloadedMeshExecutable.from_hlo\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2905\u001b[0m       mesh \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mmesh  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2906\u001b[0m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 2908\u001b[0m xla_executable, compile_options \u001b[38;5;241m=\u001b[39m \u001b[43m_cached_compilation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspmd_lowering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtuple_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_spmd_lowering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_prop_to_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_prop_to_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmap_nreps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_options_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_replicated\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2915\u001b[0m   semantics_in_shardings \u001b[38;5;241m=\u001b[39m SemanticallyEqualShardings(\n\u001b[1;32m   2916\u001b[0m       in_shardings, global_in_avals)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2718\u001b[0m, in \u001b[0;36m_cached_compilation\u001b[0;34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, allow_prop_to_inputs, allow_prop_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_keys, compiler_options_values)\u001b[0m\n\u001b[1;32m   2713\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, compile_options\n\u001b[1;32m   2715\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mlog_elapsed_time(\n\u001b[1;32m   2716\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{fun_name}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{elapsed_time}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2717\u001b[0m     fun_name\u001b[38;5;241m=\u001b[39mname, event\u001b[38;5;241m=\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mBACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 2718\u001b[0m   xla_executable \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_or_get_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2719\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xla_executable, compile_options\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/compiler.py:333\u001b[0m, in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, devices, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m    323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _compile_and_write_autotune_config(\n\u001b[1;32m    324\u001b[0m       backend,\n\u001b[1;32m    325\u001b[0m       computation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m       cache_key,\n\u001b[1;32m    331\u001b[0m   )\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_and_write_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/compiler.py:500\u001b[0m, in \u001b[0;36m_compile_and_write_cache\u001b[0;34m(backend, computation, compile_options, host_callbacks, module_name, cache_key)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compile_and_write_cache\u001b[39m(\n\u001b[1;32m    492\u001b[0m     backend: xc\u001b[38;5;241m.\u001b[39mClient,\n\u001b[1;32m    493\u001b[0m     computation: ir\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m     cache_key: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    498\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m xc\u001b[38;5;241m.\u001b[39mLoadedExecutable:\n\u001b[1;32m    499\u001b[0m   start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 500\u001b[0m   executable \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   compile_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    504\u001b[0m   _cache_write(\n\u001b[1;32m    505\u001b[0m       cache_key, compile_time, module_name, backend, executable, host_callbacks\n\u001b[1;32m    506\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/profiler.py:335\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/compiler.py:238\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(built_c, compile_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    234\u001b[0m                          host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"class DPOConfig(BaseModel):\n    env_name: Literal[\n        \"minatar-breakout\",\n        \"minatar-freeway\",\n        \"minatar-space_invaders\",\n        \"minatar-asterix\",\n        \"minatar-seaquest\",\n    ] = \"minatar-space_invaders\" \n    seed: int = 2\n    lr: float = 5e-4  \n    num_envs: int = 2048 \n    num_eval_envs: int = 128  \n    num_steps: int = 5  \n    total_timesteps: int = 10000000  \n    update_epochs: int = 4 \n    minibatch_size: int = 1024 \n    num_minibatches: int = 32  \n    gamma: float = 0.99\n    gae_lambda: float = 0.95\n    clip_eps: float = 0.25\n    ent_coef: float = 0.01\n    vf_coef: float = 0.5\n    max_grad_norm: float = 8.0\n    dpo_alpha: float = 8.0\n    dpo_beta: float = 0.6\n    wandb_entity: str = \"nonarruginitocalamarodiferro-usi\"\n    wandb_project: str = \"pgx-minatar-ppo\"\n    save_model: bool = False\n\n    class Config:\n        extra = \"forbid\"\n\nargs = DPOConfig()\n\nenv = pgx.make(str(args.env_name))\n\nnum_updates = args.total_timesteps // args.num_envs // args.num_steps\nnum_minibatches = args.num_envs * args.num_steps // args.minibatch_size\n\n# Modifica della rete ActorCritic per 1 hidden layer con 128 unità\nclass ActorCritic(hk.Module):\n    def __init__(self, num_actions):\n        super().__init__()\n        self.num_actions = num_actions\n\n    def __call__(self, x):\n        x = x.astype(jnp.float32)\n        # Un singolo hidden layer con 128 unità\n        x = x.reshape((x.shape[0], -1))  # Flatten\n        x = hk.Linear(128)(x)  # Hidden layer con 128 unità\n        x = jax.nn.relu(x)  # Attivazione relu\n\n        actor_mean = hk.Linear(self.num_actions)(x)\n\n        critic = hk.Linear(1)(x)\n\n        return actor_mean, jnp.squeeze(critic, axis=-1)\n\ndef forward_fn(x, is_eval=False):\n    net = ActorCritic(env.num_actions)\n    logits, value = net(x)\n    return logits, value\n\nforward = hk.without_apply_rng(hk.transform(forward_fn))\n\noptimizer = optax.chain(\n    optax.clip_by_global_norm(args.max_grad_norm),\n    optax.adam(args.lr, eps=1e-5)\n)\n\nclass Transition(NamedTuple):\n    done: jnp.ndarray\n    action: jnp.ndarray\n    value: jnp.ndarray\n    reward: jnp.ndarray\n    log_prob: jnp.ndarray\n    obs: jnp.ndarray\n\ndef make_update_fn():\n    # TRAIN LOOP\n    def _update_step(runner_state):\n        # COLLECT TRAJECTORIES\n        step_fn = jax.vmap(auto_reset(env.step, env.init))\n\n        def _env_step(runner_state, unused):\n            params, opt_state, env_state, last_obs, rng = runner_state\n            # SELECT ACTION\n            rng, _rng = jax.random.split(rng)\n            logits, value = forward.apply(params, last_obs)\n            pi = distrax.Categorical(logits=logits)\n            action = pi.sample(seed=_rng)\n            log_prob = pi.log_prob(action)\n\n            # STEP ENV\n            rng, _rng = jax.random.split(rng)\n            keys = jax.random.split(_rng, env_state.observation.shape[0])\n            env_state = step_fn(env_state, action, keys)\n            transition = Transition(\n                env_state.terminated,\n                action,\n                value,\n                jnp.squeeze(env_state.rewards),\n                log_prob,\n                last_obs\n            )\n            runner_state = (params, opt_state, env_state,\n                            env_state.observation, rng)\n            return runner_state, transition\n\n        runner_state, traj_batch = jax.lax.scan(\n            _env_step, runner_state, None, args.num_steps\n        )\n\n        # CALCULATE ADVANTAGE\n        params, opt_state, env_state, last_obs, rng = runner_state\n        _, last_val = forward.apply(params, last_obs)\n\n        def _calculate_gae(traj_batch, last_val):\n            def _get_advantages(gae_and_next_value, transition):\n                gae, next_value = gae_and_next_value\n                done, value, reward = (\n                    transition.done,\n                    transition.value,\n                    transition.reward,\n                )\n                delta = reward + args.gamma * next_value * (1 - done) - value\n                gae = (\n                    delta\n                    + args.gamma * args.gae_lambda * (1 - done) * gae\n                )\n                return (gae, value), gae\n\n            _, advantages = jax.lax.scan(\n                _get_advantages,\n                (jnp.zeros_like(last_val), last_val),\n                traj_batch,\n                reverse=True,\n                unroll=16,\n            )\n            return advantages, advantages + traj_batch.value\n\n        advantages, targets = _calculate_gae(traj_batch, last_val)\n\n        # UPDATE NETWORK\n        def _update_epoch(update_state, unused):\n            def _update_minbatch(tup, batch_info):\n                params, opt_state = tup\n                traj_batch, advantages, targets = batch_info\n\n                def _loss_fn(params, traj_batch, gae, targets):\n                    # RERUN NETWORK\n                    logits, value = forward.apply(params, traj_batch.obs)\n                    pi = distrax.Categorical(logits=logits)\n                    log_prob = pi.log_prob(traj_batch.action)\n                \n                    # CRITIC LOSS\n                    value_pred_clipped = traj_batch.value + (\n                        value - traj_batch.value\n                    ).clip(-args.clip_eps, args.clip_eps)\n                    value_losses = jnp.square(value - targets)\n                    value_losses_clipped = jnp.square(value_pred_clipped - targets)\n                    value_loss = 0.5 * jnp.maximum(value_losses, value_losses_clipped).mean()\n                \n                    # DPO\n\n                    alpha = args.dpo_alpha\n                    beta = args.dpo_beta \n                    log_diff = log_prob - traj_batch.log_prob\n                    ratio = jnp.exp(log_diff)\n                    gae = (gae - gae.mean()) / (gae.std() + 1e-8)\n                    is_pos = (gae >= 0.0).astype(\"float32\")\n                    r1 = ratio - 1.0\n                    drift1 = nn.relu(r1 * gae - alpha * nn.tanh(r1 * gae / alpha))\n                    drift2 = nn.relu(\n                        log_diff * gae - beta * nn.tanh(log_diff * gae / beta)\n                    )\n                    drift = drift1 * is_pos + drift2 * (1 - is_pos)\n                    loss_actor = -(ratio * gae - drift).mean()\n\n                    entropy = pi.entropy().mean()\n                \n                    # TOTAL LOSS\n                    total_loss = (\n                        loss_actor\n                        + args.vf_coef * value_loss\n                        - args.ent_coef * entropy\n                    )\n                    return total_loss, (value_loss, loss_actor, entropy)\n\n                grad_fn = jax.value_and_grad(_loss_fn, has_aux=True)\n                total_loss, grads = grad_fn(\n                    params, traj_batch, advantages, targets)\n                updates, opt_state = optimizer.update(grads, opt_state)\n                params = optax.apply_updates(params, updates)\n                return (params, opt_state), total_loss\n\n            params, opt_state, traj_batch, advantages, targets, rng = update_state\n            rng, _rng = jax.random.split(rng)\n            batch_size = args.minibatch_size * num_minibatches\n            assert (\n                batch_size == args.num_steps * args.num_envs\n            ), \"batch size must be equal to number of steps * number of envs\"\n            permutation = jax.random.permutation(_rng, batch_size)\n            batch = (traj_batch, advantages, targets)\n            batch = jax.tree_util.tree_map(\n                lambda x: x.reshape((batch_size,) + x.shape[2:]), batch\n            )\n            shuffled_batch = jax.tree_util.tree_map(\n                lambda x: jnp.take(x, permutation, axis=0), batch\n            )\n            minibatches = jax.tree_util.tree_map(\n                lambda x: jnp.reshape(\n                    x, [num_minibatches, -1] + list(x.shape[1:])\n                ),\n                shuffled_batch,\n            )\n            (params, opt_state),  total_loss = jax.lax.scan(\n                _update_minbatch, (params, opt_state), minibatches\n            )\n            update_state = (params, opt_state, traj_batch,\n                            advantages, targets, rng)\n            return update_state, total_loss\n\n        update_state = (params, opt_state, traj_batch,\n                        advantages, targets, rng)\n        update_state, loss_info = jax.lax.scan(\n            _update_epoch, update_state, None, args.update_epochs\n        )\n        params, opt_state, _, _, _, rng = update_state\n\n        runner_state = (params, opt_state, env_state, last_obs, rng)\n        return runner_state, loss_info\n    return _update_step\n\n\n@jax.jit\ndef evaluate(params, rng_key):\n    step_fn = jax.vmap(env.step)\n    rng_key, sub_key = jax.random.split(rng_key)\n    subkeys = jax.random.split(sub_key, args.num_eval_envs)\n    state = jax.vmap(env.init)(subkeys)\n    R = jnp.zeros_like(state.rewards)\n\n    def cond_fn(tup):\n        state, _, _ = tup\n        return ~state.terminated.all()\n\n    def loop_fn(tup):\n        state, R, rng_key = tup\n        logits, value = forward.apply(params, state.observation)\n        # action = logits.argmax(axis=-1)\n        pi = distrax.Categorical(logits=logits)\n        rng_key, _rng = jax.random.split(rng_key)\n        action = pi.sample(seed=_rng)\n        rng_key, _rng = jax.random.split(rng_key)\n        keys = jax.random.split(_rng, state.observation.shape[0])\n        state = step_fn(state, action, keys)\n        return state, R + state.rewards, rng_key\n    state, R, _ = jax.lax.while_loop(cond_fn, loop_fn, (state, R, rng_key))\n    return R.mean()\n\n\ndef train(rng):\n    tt = 0\n    st = time.time()\n    # INIT NETWORK\n    rng, _rng = jax.random.split(rng)\n    init_x = jnp.zeros((1, ) + env.observation_shape)\n    params = forward.init(_rng, init_x)\n    opt_state = optimizer.init(params=params)\n\n    # INIT UPDATE FUNCTION\n    _update_step = make_update_fn()\n    jitted_update_step = jax.jit(_update_step)\n\n    # INIT ENV\n    rng, _rng = jax.random.split(rng)\n    reset_rng = jax.random.split(_rng, args.num_envs)\n    env_state = jax.jit(jax.vmap(env.init))(reset_rng)\n\n    rng, _rng = jax.random.split(rng)\n    runner_state = (params, opt_state, env_state, env_state.observation, _rng)\n\n    # warm up\n    _, _ = jitted_update_step(runner_state)\n\n    steps = 0\n\n    # initial evaluation\n    et = time.time()  # exclude evaluation time\n    tt += et - st\n    rng, _rng = jax.random.split(rng)\n    eval_R = evaluate(runner_state[0], _rng)\n    log = {\"sec\": tt, f\"{args.env_name}/eval_R\": float(eval_R), \"steps\": steps}\n    print(log)\n    wandb.log(log)\n    st = time.time()\n\n    for i in range(num_updates):\n        runner_state, loss_info = jitted_update_step(runner_state)\n        steps += args.num_envs * args.num_steps\n\n        # evaluation\n        et = time.time()  # exclude evaluation time\n        tt += et - st\n        rng, _rng = jax.random.split(rng)\n        eval_R = evaluate(runner_state[0], _rng)\n        log = {\"sec\": tt, f\"{args.env_name}/eval_R\": float(eval_R), \"steps\": steps}\n        print(log)\n        wandb.log(log)\n        st = time.time()\n\n    return runner_state\n\nif __name__ == \"__main__\":\n    wandb.init(project=args.wandb_project, entity=args.wandb_entity, config=args.dict())\n    rng = jax.random.PRNGKey(args.seed)\n    out = train(rng)\n    if args.save_model:\n        with open(f\"{args.env_name}-seed={args.seed}.ckpt\", \"wb\") as f:\n            pickle.dump(out[0], f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T18:11:52.473018Z","iopub.execute_input":"2024-12-07T18:11:52.473337Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:u49gt8zd) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.121 MB of 0.121 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>minatar-space_invaders/eval_R</td><td>▁▁▁▂▂▃▃▃▄▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▅▆▅▆▆▇▇▆▆▇▇███</td></tr><tr><td>sec</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>steps</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>minatar-space_invaders/eval_R</td><td>145.67188</td></tr><tr><td>sec</td><td>10.36564</td></tr><tr><td>steps</td><td>12503040</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gentle-wave-79</strong> at: <a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo/runs/u49gt8zd' target=\"_blank\">https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo/runs/u49gt8zd</a><br/> View project at: <a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo' target=\"_blank\">https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241207_175252-u49gt8zd/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:u49gt8zd). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241207_181152-124fidu0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo/runs/124fidu0' target=\"_blank\">silvery-energy-80</a></strong> to <a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo' target=\"_blank\">https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo/runs/124fidu0' target=\"_blank\">https://wandb.ai/nonarruginitocalamarodiferro-usi/pgx-minatar-ppo/runs/124fidu0</a>"},"metadata":{}},{"name":"stdout","text":"{'sec': 3.587453842163086, 'minatar-space_invaders/eval_R': 4.1640625, 'steps': 0}\n{'sec': 3.5949692726135254, 'minatar-space_invaders/eval_R': 3.2734375, 'steps': 10240}\n{'sec': 3.6001315116882324, 'minatar-space_invaders/eval_R': 3.765625, 'steps': 20480}\n{'sec': 3.60487699508667, 'minatar-space_invaders/eval_R': 3.0390625, 'steps': 30720}\n{'sec': 3.6099936962127686, 'minatar-space_invaders/eval_R': 3.125, 'steps': 40960}\n{'sec': 3.614887237548828, 'minatar-space_invaders/eval_R': 3.609375, 'steps': 51200}\n{'sec': 3.6198906898498535, 'minatar-space_invaders/eval_R': 3.421875, 'steps': 61440}\n{'sec': 3.6247944831848145, 'minatar-space_invaders/eval_R': 3.6953125, 'steps': 71680}\n{'sec': 3.629664182662964, 'minatar-space_invaders/eval_R': 5.2890625, 'steps': 81920}\n{'sec': 3.6349616050720215, 'minatar-space_invaders/eval_R': 5.5859375, 'steps': 92160}\n{'sec': 3.6398162841796875, 'minatar-space_invaders/eval_R': 5.75, 'steps': 102400}\n{'sec': 3.644583225250244, 'minatar-space_invaders/eval_R': 7.3984375, 'steps': 112640}\n{'sec': 3.6494414806365967, 'minatar-space_invaders/eval_R': 6.3046875, 'steps': 122880}\n{'sec': 3.654228448867798, 'minatar-space_invaders/eval_R': 7.078125, 'steps': 133120}\n{'sec': 3.6592493057250977, 'minatar-space_invaders/eval_R': 6.171875, 'steps': 143360}\n{'sec': 3.664224863052368, 'minatar-space_invaders/eval_R': 6.5078125, 'steps': 153600}\n{'sec': 3.6692075729370117, 'minatar-space_invaders/eval_R': 5.890625, 'steps': 163840}\n{'sec': 3.6743040084838867, 'minatar-space_invaders/eval_R': 6.203125, 'steps': 174080}\n{'sec': 3.6795458793640137, 'minatar-space_invaders/eval_R': 6.8125, 'steps': 184320}\n{'sec': 3.68465518951416, 'minatar-space_invaders/eval_R': 7.4296875, 'steps': 194560}\n{'sec': 3.689788341522217, 'minatar-space_invaders/eval_R': 7.8984375, 'steps': 204800}\n{'sec': 3.6950159072875977, 'minatar-space_invaders/eval_R': 8.25, 'steps': 215040}\n{'sec': 3.7002763748168945, 'minatar-space_invaders/eval_R': 9.5078125, 'steps': 225280}\n{'sec': 3.705483913421631, 'minatar-space_invaders/eval_R': 9.171875, 'steps': 235520}\n{'sec': 3.710550546646118, 'minatar-space_invaders/eval_R': 10.109375, 'steps': 245760}\n{'sec': 3.715700387954712, 'minatar-space_invaders/eval_R': 9.9375, 'steps': 256000}\n{'sec': 3.720862865447998, 'minatar-space_invaders/eval_R': 10.75, 'steps': 266240}\n{'sec': 3.7261219024658203, 'minatar-space_invaders/eval_R': 10.421875, 'steps': 276480}\n{'sec': 3.7313339710235596, 'minatar-space_invaders/eval_R': 11.1171875, 'steps': 286720}\n{'sec': 3.736668348312378, 'minatar-space_invaders/eval_R': 12.2109375, 'steps': 296960}\n{'sec': 3.7420260906219482, 'minatar-space_invaders/eval_R': 12.1640625, 'steps': 307200}\n{'sec': 3.7472169399261475, 'minatar-space_invaders/eval_R': 12.015625, 'steps': 317440}\n{'sec': 3.752537250518799, 'minatar-space_invaders/eval_R': 13.6640625, 'steps': 327680}\n{'sec': 3.757772445678711, 'minatar-space_invaders/eval_R': 12.90625, 'steps': 337920}\n{'sec': 3.7631676197052, 'minatar-space_invaders/eval_R': 13.890625, 'steps': 348160}\n{'sec': 3.7685399055480957, 'minatar-space_invaders/eval_R': 13.6953125, 'steps': 358400}\n{'sec': 3.7739369869232178, 'minatar-space_invaders/eval_R': 14.5078125, 'steps': 368640}\n{'sec': 3.7793920040130615, 'minatar-space_invaders/eval_R': 15.359375, 'steps': 378880}\n{'sec': 3.784811019897461, 'minatar-space_invaders/eval_R': 16.1953125, 'steps': 389120}\n{'sec': 3.790188789367676, 'minatar-space_invaders/eval_R': 15.7578125, 'steps': 399360}\n{'sec': 3.796048164367676, 'minatar-space_invaders/eval_R': 18.0, 'steps': 409600}\n{'sec': 3.8016340732574463, 'minatar-space_invaders/eval_R': 16.984375, 'steps': 419840}\n{'sec': 3.807110548019409, 'minatar-space_invaders/eval_R': 17.15625, 'steps': 430080}\n{'sec': 3.8124420642852783, 'minatar-space_invaders/eval_R': 18.8984375, 'steps': 440320}\n{'sec': 3.818040370941162, 'minatar-space_invaders/eval_R': 18.7421875, 'steps': 450560}\n{'sec': 3.823554277420044, 'minatar-space_invaders/eval_R': 17.7421875, 'steps': 460800}\n{'sec': 3.829263687133789, 'minatar-space_invaders/eval_R': 22.0234375, 'steps': 471040}\n{'sec': 3.8349502086639404, 'minatar-space_invaders/eval_R': 19.125, 'steps': 481280}\n{'sec': 3.8405067920684814, 'minatar-space_invaders/eval_R': 19.2578125, 'steps': 491520}\n{'sec': 3.8463921546936035, 'minatar-space_invaders/eval_R': 20.0859375, 'steps': 501760}\n{'sec': 3.8520421981811523, 'minatar-space_invaders/eval_R': 18.8515625, 'steps': 512000}\n{'sec': 3.8576064109802246, 'minatar-space_invaders/eval_R': 18.25, 'steps': 522240}\n{'sec': 3.8632538318634033, 'minatar-space_invaders/eval_R': 19.1875, 'steps': 532480}\n{'sec': 3.8687140941619873, 'minatar-space_invaders/eval_R': 22.0546875, 'steps': 542720}\n{'sec': 3.874622106552124, 'minatar-space_invaders/eval_R': 20.8203125, 'steps': 552960}\n{'sec': 3.8801486492156982, 'minatar-space_invaders/eval_R': 22.140625, 'steps': 563200}\n{'sec': 3.885864019393921, 'minatar-space_invaders/eval_R': 21.75, 'steps': 573440}\n{'sec': 3.8914899826049805, 'minatar-space_invaders/eval_R': 20.828125, 'steps': 583680}\n{'sec': 3.8971362113952637, 'minatar-space_invaders/eval_R': 23.71875, 'steps': 593920}\n{'sec': 3.9029035568237305, 'minatar-space_invaders/eval_R': 23.984375, 'steps': 604160}\n{'sec': 3.908437728881836, 'minatar-space_invaders/eval_R': 24.4296875, 'steps': 614400}\n{'sec': 3.914267063140869, 'minatar-space_invaders/eval_R': 24.640625, 'steps': 624640}\n{'sec': 3.9200799465179443, 'minatar-space_invaders/eval_R': 21.3984375, 'steps': 634880}\n{'sec': 3.9260549545288086, 'minatar-space_invaders/eval_R': 24.2421875, 'steps': 645120}\n{'sec': 3.9319028854370117, 'minatar-space_invaders/eval_R': 24.2421875, 'steps': 655360}\n{'sec': 3.93766713142395, 'minatar-space_invaders/eval_R': 28.7421875, 'steps': 665600}\n{'sec': 3.943441390991211, 'minatar-space_invaders/eval_R': 27.484375, 'steps': 675840}\n{'sec': 3.949188232421875, 'minatar-space_invaders/eval_R': 28.7578125, 'steps': 686080}\n{'sec': 3.9549636840820312, 'minatar-space_invaders/eval_R': 28.265625, 'steps': 696320}\n{'sec': 3.9606146812438965, 'minatar-space_invaders/eval_R': 29.234375, 'steps': 706560}\n{'sec': 3.9661550521850586, 'minatar-space_invaders/eval_R': 28.96875, 'steps': 716800}\n{'sec': 3.971781015396118, 'minatar-space_invaders/eval_R': 27.4375, 'steps': 727040}\n{'sec': 3.9774014949798584, 'minatar-space_invaders/eval_R': 26.71875, 'steps': 737280}\n{'sec': 3.9829530715942383, 'minatar-space_invaders/eval_R': 28.8828125, 'steps': 747520}\n{'sec': 3.988985061645508, 'minatar-space_invaders/eval_R': 27.7265625, 'steps': 757760}\n","output_type":"stream"}],"execution_count":null}]}